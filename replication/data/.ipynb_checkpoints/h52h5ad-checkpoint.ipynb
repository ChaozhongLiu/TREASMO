{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd0b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import scipy as sp\n",
    "\n",
    "#plt.figure(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0281e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a data reader\n",
    "class DataReader:\n",
    "    \n",
    "    def __init__(self, data_dir, filename, metadata_file_name):\n",
    "        self.filename = filename\n",
    "        self.prefix = filename.replace('.h5','')\n",
    "        self.file_path = os.path.join(data_dir, filename)\n",
    "        self.md = pd.read_csv(metadata_file_name)\n",
    "    \n",
    "    def get_query_metadata(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Filters metadata according to variable query args (kwargs).\n",
    "        \"\"\"\n",
    "        qmd = self.md.copy()\n",
    "        for arg in kwargs:\n",
    "            qmd = qmd.loc[qmd[arg] == kwargs[arg]].copy()\n",
    "            \n",
    "        return qmd\n",
    "    \n",
    "    def get_nb_of_rows(self):\n",
    "        f = h5py.File(self.file_path,'r')\n",
    "        nrows = f[self.filename.replace('.h5','')]['axis1'].shape[0]\n",
    "        return nrows\n",
    "    \n",
    "    def query_data(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This function uses h5py to query the file. It returns a dataframe (which might well be huge). Depending on your query,\n",
    "        you might still run out of RAM and your session crash. Call it like:\n",
    "        \n",
    "        Examples:\n",
    "        query_data(day = day_nb, donor = donor_nb, cell_type = some_type_you_want)\n",
    "        query_data(day = day_nb, cell_type = some_type_you_want)\n",
    "        query_data(day = day_nb) <-- Beware: this might return lots of data that do not fit into RAM, especially for multiome files.\n",
    "        query_data(donor = donor_nb) <-- Same remark holds.\n",
    "        \"\"\"\n",
    "        \n",
    "        f = h5py.File(self.file_path, 'r')\n",
    "        query_df = self.get_query_metadata(**kwargs)\n",
    "\n",
    "        ax1 = f[self.prefix]['axis1'][:]\n",
    "        ax1 = list(map(lambda x: x.decode(), ax1))\n",
    "        ax1 = pd.DataFrame(ax1, columns = ['cell_id']).reset_index().\\\n",
    "        rename(columns = {'index':'index_col'})\n",
    "        ax1 = pd.merge(query_df[['cell_id','day','donor','cell_type']]\n",
    "                      ,ax1\n",
    "                      ,on = 'cell_id').sort_values(by = 'index_col')\n",
    "        #ax1 = ax1.iloc[0:50,:]\n",
    "        \n",
    "        out = f[self.prefix]['block0_values'][ax1.index_col.values,:]\n",
    "        columns = [col.decode() for col in f[self.prefix]['axis0'][:]]\n",
    "        out = pd.DataFrame(out, index = ax1.cell_id, columns = columns)\n",
    "        \n",
    "        f.close()\n",
    "\n",
    "        return out, ax1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61dae56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def h52h5ad(input_file, sparse=False, chosen_for_train=True):\n",
    "    dr_atac = DataReader('./raw/', input_file, 'raw/metadata.csv')\n",
    "    start = time.time()\n",
    "    mtx_tmp, meta_tmp = dr_atac.query_data(chosen_for_train=chosen_for_train)\n",
    "    print('h5 query extraction done! %.2fs past.'%(time.time()-start))\n",
    "    \n",
    "    meta_tmp.index = meta_tmp['cell_id']\n",
    "    \n",
    "    anndat_out = ad.AnnData(\n",
    "        X = mtx_tmp, #.to_numpy()\n",
    "        obs = meta_tmp,\n",
    "    )\n",
    "    \n",
    "    if sparse:\n",
    "        anndat_out.X = sp.sparse.csc_matrix(anndat_out.X)\n",
    "    \n",
    "    return anndat_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c7895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5 file saved in ./raw/ together with metadata.csv\n",
    "multiome_atac_file = 'train_multi_inputs.h5'\n",
    "multiome_rna_file = 'train_multi_targets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c47f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 query extraction done! 111.57s past.\n"
     ]
    }
   ],
   "source": [
    "anndat_rnam = h52h5ad(multiome_rna_file)\n",
    "anndat_rnam.write_h5ad('h5ad/HSPC_Multiome_RNA.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a190d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 query extraction done! 622.48s past.\n"
     ]
    }
   ],
   "source": [
    "anndat_atac = h52h5ad(multiome_atac_file)\n",
    "anndat_atac.write_h5ad('h5ad/HSPC_Multiome_ATAC.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treasmo",
   "language": "python",
   "name": "treasmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
